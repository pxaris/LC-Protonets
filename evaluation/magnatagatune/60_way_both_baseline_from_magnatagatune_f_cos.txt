
Evaluation of model "magnatagatune/baseline_from_magnatagatune_f_cos" on "magnatagatune" test set, with
- N-way: 60
- K-shot: 3
- distance: cos

Test set evaluation:
- macro-f1: 0.20831170607310157
- micro-f1: 0.21454952964202287


Classification report:
               precision    recall  f1-score   support

       female       0.28      0.90      0.43       368
         beat       0.18      0.99      0.30       334
        sitar       0.04      0.97      0.08        96
 female voice       0.07      0.91      0.13       116
      electro       0.03      1.00      0.07        73
      new age       0.06      0.95      0.11       143
         jazz       0.03      0.89      0.05        83
          pop       0.10      0.96      0.19       192
         male       0.16      0.94      0.28       254
   male vocal       0.11      0.90      0.19       161
       techno       0.34      0.98      0.51       590
        voice       0.09      0.74      0.16       137
        cello       0.01      1.00      0.01        16
    no vocals       0.08      0.86      0.15       238
        flute       0.07      0.95      0.12       159
    classical       0.30      0.97      0.46       690
       choral       0.10      1.00      0.18       126
   electronic       0.25      0.97      0.40       488
       indian       0.05      0.64      0.09       169
        dance       0.09      0.99      0.16       150
      classic       0.05      0.96      0.09       106
         loud       0.12      0.94      0.21       267
female vocals       0.07      0.92      0.13        95
 female vocal       0.12      0.95      0.21       156
       violin       0.09      0.93      0.17       227
       vocals       0.16      0.92      0.27       273
        choir       0.16      1.00      0.27       183
   male voice       0.07      0.90      0.14       117
    hard rock       0.06      1.00      0.11        84
      singing       0.19      0.91      0.31       283
       chorus       0.06      0.99      0.11        68
     no vocal       0.07      0.84      0.12       187
         harp       0.07      0.96      0.12       138
        drums       0.24      0.95      0.38       503
        opera       0.25      1.00      0.40       362
      ambient       0.23      0.98      0.37       499
         solo       0.07      0.92      0.13       156
        vocal       0.27      0.88      0.42       422
     no voice       0.03      0.69      0.06       112
         drum       0.04      0.92      0.07        77
         rock       0.32      0.99      0.49       558
         soft       0.10      0.89      0.17       246
          man       0.06      0.89      0.12       132
        quiet       0.10      0.91      0.18       243
        beats       0.08      0.99      0.15       139
       guitar       0.33      0.90      0.48       862
         fast       0.21      0.96      0.34       487
        weird       0.05      0.86      0.10       127
      foreign       0.04      0.89      0.08        62
        metal       0.11      1.00      0.19       161
  male vocals       0.06      0.93      0.10        84
      country       0.03      1.00      0.06        65
     no piano       0.01      0.41      0.03        64
 instrumental       0.02      0.81      0.05        72
      strings       0.16      0.97      0.28       383
         slow       0.29      0.88      0.44       790
        piano       0.19      0.94      0.31       463
  harpsichord       0.08      0.99      0.16       186
        synth       0.17      0.97      0.29       325
        woman       0.19      0.93      0.32       241

    micro avg       0.12      0.93      0.21     14588
    macro avg       0.12      0.92      0.21     14588
 weighted avg       0.19      0.93      0.30     14588
  samples avg       0.12      0.94      0.21     14588


[INFO]
- Method: baseline
- # Prototypes: 60
- # Unique items in support set: 61
- # Unique items in query set: 4271
- Mean groung truth labels per item: 3.42
- Mean predicted labels per item: 26.25

Execution time: 24 seconds
